@article{learnedcardinality,
  author       = {Xiaoying Wang and
                  Changbo Qu and
                  Weiyuan Wu and
                  Jiannan Wang and
                  Qingqing Zhou},
  title        = {Are We Ready For Learned Cardinality Estimation?},
  journal      = {CoRR},
  volume       = {abs/2012.06743},
  year         = {2020},
  url          = {https://arxiv.org/abs/2012.06743},
  eprinttype    = {arXiv},
  eprint       = {2012.06743},
  timestamp    = {Sun, 21 Sep 2025 18:00:18 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2012-06743.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{heule2013hyperloglog,
author = {Heule, Stefan and Nunkesser, Marc and Hall, Alexander},
title = {HyperLogLog in practice: algorithmic engineering of a state of the art cardinality estimation algorithm},
year = {2013},
isbn = {9781450315975},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2452376.2452456},
doi = {10.1145/2452376.2452456},
abstract = {Cardinality estimation has a wide range of applications and is of particular importance in database systems. Various algorithms have been proposed in the past, and the HyperLogLog algorithm is one of them. In this paper, we present a series of improvements to this algorithm that reduce its memory requirements and significantly increase its accuracy for an important range of cardinalities. We have implemented our proposed algorithm for a system at Google and evaluated it empirically, comparing it to the original HyperLogLog algorithm. Like HyperLogLog, our improved algorithm parallelizes perfectly and computes the cardinality estimate in a single pass.},
booktitle = {Proceedings of the 16th International Conference on Extending Database Technology},
pages = {683–692},
numpages = {10},
location = {Genoa, Italy},
series = {EDBT '13}
}

@article{kraska2017learnedindex,
  author       = {Tim Kraska and
                  Alex Beutel and
                  Ed H. Chi and
                  Jeffrey Dean and
                  Neoklis Polyzotis},
  title        = {The Case for Learned Index Structures},
  journal      = {CoRR},
  volume       = {abs/1712.01208},
  year         = {2017},
  url          = {http://arxiv.org/abs/1712.01208},
  eprinttype    = {arXiv},
  eprint       = {1712.01208},
  timestamp    = {Mon, 13 Aug 2018 16:48:19 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1712-01208.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{dai2019adabf,
  author       = {Zhenwei Dai and
                  Anshumali Shrivastava},
  title        = {Adaptive Learned Bloom Filter (Ada-BF): Efficient Utilization of the
                  Classifier},
  journal      = {CoRR},
  volume       = {abs/1910.09131},
  year         = {2019},
  url          = {http://arxiv.org/abs/1910.09131},
  eprinttype    = {arXiv},
  eprint       = {1910.09131},
  timestamp    = {Tue, 22 Oct 2019 18:17:16 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1910-09131.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{mitzenmacher2020predictions,
  author       = {Michael Mitzenmacher and
                  Sergei Vassilvitskii},
  title        = {Algorithms with Predictions},
  journal      = {CoRR},
  volume       = {abs/2006.09123},
  year         = {2020},
  url          = {https://arxiv.org/abs/2006.09123},
  eprinttype    = {arXiv},
  eprint       = {2006.09123},
  timestamp    = {Wed, 17 Jun 2020 14:28:54 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2006-09123.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{flajolet2007hyperloglog,
    title      = {HyperLogLog: the analysis of a near-optimal cardinality estimation algorithm},
    author     = {Philippe Flajolet and Éric Fusy and Olivier Gandouet and Frédéric Meunier},
    url        = {https://dmtcs.episciences.org/3545},
    doi        = {10.46298/dmtcs.3545},
    journal    = {Discrete Mathematics \& Theoretical Computer Science},
    issn       = {1365-8050},
    volume     = {DMTCS Proceedings vol. AH, 2007 Conference on Analysis of Algorithms (AofA 07)},
    issuetitle = {Proceedings},
    eid        = 10,
    year       = {2007},
    month      = {Jan},
    keywords   = {cardinality estimation, Probabilistic algorithm, [INFO.INFO-DS]Computer Science [cs]/Data Structures and Algorithms [cs.DS], [INFO.INFO-DM]Computer Science [cs]/Discrete Mathematics [cs.DM], [MATH.MATH-CO]Mathematics [math]/Combinatorics [math.CO], [INFO.INFO-CG]Computer Science [cs]/Computational Geometry [cs.CG]},
    language   = {English},
}

@article{mitzenmacher2018learnedbloomfilter,
    author       = {Michael Mitzenmacher},
    title        = {A Model for Learned Bloom Filters and Related Structures},
    journal      = {CoRR},
    volume       = {abs/1802.00884},
    year         = {2018},
    url          = {http://arxiv.org/abs/1802.00884},
    eprinttype    = {arXiv},
    eprint       = {1802.00884},
    timestamp    = {Mon, 13 Aug 2018 16:46:35 +0200},
    biburl       = {https://dblp.org/rec/journals/corr/abs-1802-00884.bib},
    bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@misc{kenneth2021adversarial,
    author = {Kenneth G.  Paterson and Mathilde Raynal},
    title = {{HyperLogLog}: Exponentially Bad in Adversarial Settings},
    howpublished = {Cryptology {ePrint} Archive, Paper 2021/1139},
    year = {2021},
    url = {https://eprint.iacr.org/2021/1139}
}

@inproceedings{Ma2021LearnedAQ,
  title={Learned Approximate Query Processing: Make it Light, Accurate and Fast},
  author={Qingzhi Ma and Ali Mohammadi Shanghooshabad and Mehrdad Almasi and Meghdad Kurmanji and P. Triantafillou},
  booktitle={Conference on Innovative Data Systems Research},
  year={2021},
  url={https://api.semanticscholar.org/CorpusID:232328138}
}

@article{DBLP:journals/corr/abs-1802-05399,
  author       = {Thodoris Lykouris and
                  Sergei Vassilvitskii},
  title        = {Competitive caching with machine learned advice},
  journal      = {CoRR},
  volume       = {abs/1802.05399},
  year         = {2018},
  url          = {http://arxiv.org/abs/1802.05399},
  eprinttype    = {arXiv},
  eprint       = {1802.05399},
  timestamp    = {Mon, 13 Aug 2018 16:48:42 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1802-05399.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@misc{anand2022customizingmlpredictionsonline,
      title={Customizing ML Predictions for Online Algorithms}, 
      author={Keerti Anand and Rong Ge and Debmalya Panigrahi},
      year={2022},
      eprint={2205.08715},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2205.08715}, 
}

@article{DBLP:journals/corr/Ertl17,
  author       = {Otmar Ertl},
  title        = {New cardinality estimation algorithms for HyperLogLog sketches},
  journal      = {CoRR},
  volume       = {abs/1702.01284},
  year         = {2017},
  url          = {http://arxiv.org/abs/1702.01284},
  eprinttype    = {arXiv},
  eprint       = {1702.01284},
  timestamp    = {Mon, 13 Aug 2018 16:48:24 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/Ertl17.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{b801a9734ab04fae9930bc40ef10ed8c,
title = "A Learned Sketch for Subgraph Counting",
abstract = "Subgraph counting, as a fundamental problem in network analysis, is to count the number of subgraphs in a data graph that match a given query graph by either homomorphism or subgraph isomorphism. The importance of subgraph counting derives from the fact that it provides insights of a large graph, in particular a labeled graph, when a collection of query graphs with different sizes and labels are issued. The problem of counting is challenging. On one hand, exact counting by enumerating subgraphs is NP-hard. \% On the other hand, approximate counting by subgraph isomorphism can only support 3/5-node query graphs over unlabeled graphs. \% Another way for subgraph counting is to specify it as an \textbackslash{}SQL query and estimate the cardinality of the query in \textbackslash{}rdbm. Existing approaches for cardinality estimation can only support subgraph counting by homomorphism up to some extent, as it is difficult to deal with sampling failure when a query graph becomes large. A question that arises is if subgraph counting can be supported by machine learning (ML) and deep learning (DL). The existing DL approach for subgraph isomorphism can only support small data graphs. The ML/DL approaches proposed in \textbackslash{}rdbm context for approximate query processing and cardinality estimation cannot be used, as subgraph counting is to do complex self-joins over one relation, whereas existing approaches focus on multiple relations. In this paper, we propose an Active Learned Sketch for Subgraph Counting (\textbackslash{}ALSS) with two main components: a sketch learned ({\L}SS) and an active learner (\textbackslash{}AL). The sketch is learned by a neural network regression model, and the active learner is to perform model updates based on new arrival test query graphs. \% We conduct extensive experimental studies to confirm the effectiveness and efficiency of \textbackslash{}ALSS using large real labeled graphs. Moreover, we show that \textbackslash{}ALSS can assist query optimizers to find a better query plan for complex multi-way self-joins.",
keywords = "deep learning, subgraph counting",
author = "Kangfei Zhao and Yu, \{Jeffrey Xu\} and Hao Zhang and Qiyan Li and Yu Rong",
note = "Publisher Copyright: {\textcopyright} 2021 ACM.; 2021 International Conference on Management of Data, SIGMOD 2021 ; Conference date: 20-06-2021 Through 25-06-2021",
year = "2021",
doi = "10.1145/3448016.3457289",
language = "English",
pages = "2142--2155",
journal = "Proceedings of the ACM SIGMOD International Conference on Management of Data",
issn = "0730-8078",
}

@article{10.1145/3639321,
author = {Tsan, Brian and Datta, Asoke and Izenov, Yesdaulet and Rusu, Florin},
title = {Approximate Sketches},
year = {2024},
issue_date = {February 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {1},
url = {https://doi.org/10.1145/3639321},
doi = {10.1145/3639321},
abstract = {Sketches are single-pass small-space data summaries that can quickly estimate the cardinality of join queries. However, sketches are not directly applicable to join queries with dynamic filter conditions --- where arbitrary selection predicate(s) are applied --- since a sketch is limited to a fixed selection. While multiple sketches for various selections can be used in combination, they each incur individual storage and maintenance costs. Alternatively, exact sketches can be built during runtime for every selection. To make this process scale, a high-degree of parallelism --- available in hardware accelerators such as GPUs --- is required. Therefore, sketch usage for cardinality estimation in query optimization is limited. Following recent work that applies transformers to cardinality estimation, we design a novel learning-based method to approximate the sketch of any arbitrary selection, enabling sketches for join queries with filter conditions. We train a transformer on each table to estimate the sketch of any subset of the table, i.e., any arbitrary selection. Transformers achieve this by learning the joint distribution amongst table attributes, which is equivalent to a multidimensional sketch. Subsequently, transformers can approximate any sketch, enabling sketches for join cardinality estimation. In turn, estimating joins via approximate sketches allows tables to be modeled individually and thus scales linearly with the number of tables. We evaluate the accuracy and efficacy of approximate sketches on queries with selection predicates consisting of conjunctions of point and range conditions. Approximate sketches achieve similar accuracy to exact sketches with at least one order of magnitude less overhead.},
journal = {Proc. ACM Manag. Data},
month = mar,
articleno = {66},
numpages = {24},
keywords = {cardinality estimation, database sketch, neural networks, synopsis}
}

@article{aiyou2011selflearningbitmap,
title	= {Distinct counting with a self-learning bitmap},
author	= {Aiyou Chen and Jin Cao and Larry Shepp and Tuan Nguyen},
year	= {2011},journal	= {Journal of American Statistical Association},
pages	= {879–890},volume	= {106}}

@article{wu2021learnedestimator,
   title={Learning to be a statistician: learned estimator for number of distinct values},
   volume={15},
   ISSN={2150-8097},
   url={http://dx.doi.org/10.14778/3489496.3489508},
   DOI={10.14778/3489496.3489508},
   number={2},
   journal={Proceedings of the VLDB Endowment},
   publisher={Association for Computing Machinery (ACM)},
   author={Wu, Renzhi and Ding, Bolin and Chu, Xu and Wei, Zhewei and Dai, Xiening and Guan, Tao and Zhou, Jingren},
   year={2021},
   month=oct, pages={272–284} }

@article{harmouch2017cesurvey,
author = {Harmouch, Hazar and Naumann, Felix},
title = {Cardinality estimation: an experimental survey},
year = {2017},
issue_date = {December 2017},
publisher = {VLDB Endowment},
volume = {11},
number = {4},
issn = {2150-8097},
url = {https://doi.org/10.1145/3186728.3164145},
doi = {10.1145/3186728.3164145},
abstract = {Data preparation and data profiling comprise many both basic and complex tasks to analyze a dataset at hand and extract metadata, such as data distributions, key candidates, and functional dependencies. Among the most important types of metadata is the number of distinct values in a column, also known as the zeroth-frequency moment. Cardinality estimation itself has been an active research topic in the past decades due to its many applications. The aim of this paper is to review the literature of cardinality estimation and to present a detailed experimental study of twelve algorithms, scaling far beyond the original experiments.First, we outline and classify approaches to solve the problem of cardinality estimation - we describe their main idea, error-guarantees, advantages, and disadvantages. Our experimental survey then compares the performance all twelve cardinality estimation algorithms. We evaluate the algorithms' accuracy, runtime, and memory consumption using synthetic and real-world datasets. Our results show that different algorithms excel in different in categories, and we highlight their trade-offs.},
journal = {Proc. VLDB Endow.},
month = dec,
pages = {499–512},
numpages = {14}
}